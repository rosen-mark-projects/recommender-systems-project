{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    reco_utils/README.md\n",
      "A    reco_utils/__init__.py\n",
      "A    reco_utils/azureml\n",
      "A    reco_utils/azureml/__init__.py\n",
      "A    reco_utils/azureml/aks_utils.py\n",
      "A    reco_utils/azureml/azureml_designer_modules\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/map_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/ndcg_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/precision_at_k_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/recall_at_k_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/score_sar_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/stratified_splitter_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/entries/train_sar_entry.py\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/map.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/ndcg.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/precision_at_k.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/recall_at_k.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/sar_conda.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/sar_score.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/sar_train.yaml\n",
      "A    reco_utils/azureml/azureml_designer_modules/module_specs/stratified_splitter.yaml\n",
      "A    reco_utils/azureml/azureml_utils.py\n",
      "A    reco_utils/azureml/svd_training.py\n",
      "A    reco_utils/azureml/wide_deep_training.py\n",
      "A    reco_utils/common\n",
      "A    reco_utils/common/__init__.py\n",
      "A    reco_utils/common/constants.py\n",
      "A    reco_utils/common/general_utils.py\n",
      "A    reco_utils/common/gpu_utils.py\n",
      "A    reco_utils/common/notebook_memory_management.py\n",
      "A    reco_utils/common/notebook_utils.py\n",
      "A    reco_utils/common/plot.py\n",
      "A    reco_utils/common/python_utils.py\n",
      "A    reco_utils/common/spark_utils.py\n",
      "A    reco_utils/common/tf_utils.py\n",
      "A    reco_utils/common/timer.py\n",
      "A    reco_utils/dataset\n",
      "A    reco_utils/dataset/__init__.py\n",
      "A    reco_utils/dataset/amazon_reviews.py\n",
      "A    reco_utils/dataset/blob_utils.py\n",
      "A    reco_utils/dataset/cosmos_cli.py\n",
      "A    reco_utils/dataset/covid_utils.py\n",
      "A    reco_utils/dataset/criteo.py\n",
      "A    reco_utils/dataset/download_utils.py\n",
      "A    reco_utils/dataset/movielens.py\n",
      "A    reco_utils/dataset/pandas_df_utils.py\n",
      "A    reco_utils/dataset/python_splitters.py\n",
      "A    reco_utils/dataset/spark_splitters.py\n",
      "A    reco_utils/dataset/sparse.py\n",
      "A    reco_utils/dataset/split_utils.py\n",
      "A    reco_utils/dataset/wikidata.py\n",
      "A    reco_utils/evaluation\n",
      "A    reco_utils/evaluation/__init__.py\n",
      "A    reco_utils/evaluation/python_evaluation.py\n",
      "A    reco_utils/evaluation/spark_evaluation.py\n",
      "A    reco_utils/recommender\n",
      "A    reco_utils/recommender/__init__.py\n",
      "A    reco_utils/recommender/cornac\n",
      "A    reco_utils/recommender/cornac/__init__.py\n",
      "A    reco_utils/recommender/cornac/cornac_utils.py\n",
      "A    reco_utils/recommender/deeprec\n",
      "A    reco_utils/recommender/deeprec/__init__.py\n",
      "A    reco_utils/recommender/deeprec/config\n",
      "A    reco_utils/recommender/deeprec/config/asvd.yaml\n",
      "A    reco_utils/recommender/deeprec/config/caser.yaml\n",
      "A    reco_utils/recommender/deeprec/config/gru4rec.yaml\n",
      "A    reco_utils/recommender/deeprec/config/sli_rec.yaml\n",
      "A    reco_utils/recommender/deeprec/deeprec_utils.py\n",
      "A    reco_utils/recommender/deeprec/io\n",
      "A    reco_utils/recommender/deeprec/io/__init__.py\n",
      "A    reco_utils/recommender/deeprec/io/dkn_iterator.py\n",
      "A    reco_utils/recommender/deeprec/io/iterator.py\n",
      "A    reco_utils/recommender/deeprec/io/sequential_iterator.py\n",
      "A    reco_utils/recommender/deeprec/models\n",
      "A    reco_utils/recommender/deeprec/models/__init__.py\n",
      "A    reco_utils/recommender/deeprec/models/base_model.py\n",
      "A    reco_utils/recommender/deeprec/models/dkn.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential\n",
      "A    reco_utils/recommender/deeprec/models/sequential/asvd.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential/caser.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential/gru4rec.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential/rnn_cell_implement.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential/sequential_base_model.py\n",
      "A    reco_utils/recommender/deeprec/models/sequential/sli_rec.py\n",
      "A    reco_utils/recommender/deeprec/models/xDeepFM.py\n",
      "A    reco_utils/recommender/fastai\n",
      "A    reco_utils/recommender/fastai/__init__.py\n",
      "A    reco_utils/recommender/fastai/fastai_utils.py\n",
      "A    reco_utils/recommender/lightfm\n",
      "A    reco_utils/recommender/lightfm/__init__.py\n",
      "A    reco_utils/recommender/lightfm/lightfm_utils.py\n",
      "A    reco_utils/recommender/lightgbm\n",
      "A    reco_utils/recommender/lightgbm/__init__.py\n",
      "A    reco_utils/recommender/lightgbm/lightgbm_utils.py\n",
      "A    reco_utils/recommender/ncf\n",
      "A    reco_utils/recommender/ncf/__init__.py\n",
      "A    reco_utils/recommender/ncf/dataset.py\n",
      "A    reco_utils/recommender/ncf/ncf_singlenode.py\n",
      "A    reco_utils/recommender/newsrec\n",
      "A    reco_utils/recommender/newsrec/__init__.py\n",
      "A    reco_utils/recommender/newsrec/io\n",
      "A    reco_utils/recommender/newsrec/io/__init__.py\n",
      "A    reco_utils/recommender/newsrec/io/naml_iterator.py\n",
      "A    reco_utils/recommender/newsrec/io/news_iterator.py\n",
      "A    reco_utils/recommender/newsrec/models\n",
      "A    reco_utils/recommender/newsrec/models/__init__.py\n",
      "A    reco_utils/recommender/newsrec/models/base_model.py\n",
      "A    reco_utils/recommender/newsrec/models/layers.py\n",
      "A    reco_utils/recommender/newsrec/models/lstur.py\n",
      "A    reco_utils/recommender/newsrec/models/naml.py\n",
      "A    reco_utils/recommender/newsrec/models/npa.py\n",
      "A    reco_utils/recommender/newsrec/models/nrms.py\n",
      "A    reco_utils/recommender/newsrec/newsrec_utils.py\n",
      "A    reco_utils/recommender/rbm\n",
      "A    reco_utils/recommender/rbm/__init__.py\n",
      "A    reco_utils/recommender/rbm/rbm.py\n",
      "A    reco_utils/recommender/rlrmc\n",
      "A    reco_utils/recommender/rlrmc/RLRMCalgorithm.py\n",
      "A    reco_utils/recommender/rlrmc/RLRMCdataset.py\n",
      "A    reco_utils/recommender/rlrmc/__init__.py\n",
      "A    reco_utils/recommender/rlrmc/conjugate_gradient_ms.py\n",
      "A    reco_utils/recommender/sar\n",
      "A    reco_utils/recommender/sar/__init__.py\n",
      "A    reco_utils/recommender/sar/sar_singlenode.py\n",
      "A    reco_utils/recommender/surprise\n",
      "A    reco_utils/recommender/surprise/__init__.py\n",
      "A    reco_utils/recommender/surprise/surprise_utils.py\n",
      "A    reco_utils/recommender/tfidf\n",
      "A    reco_utils/recommender/tfidf/__init__.py\n",
      "A    reco_utils/recommender/tfidf/tfidf_utils.py\n",
      "A    reco_utils/recommender/vowpal_wabbit\n",
      "A    reco_utils/recommender/vowpal_wabbit/__init__.py\n",
      "A    reco_utils/recommender/vowpal_wabbit/vw.py\n",
      "A    reco_utils/recommender/wide_deep\n",
      "A    reco_utils/recommender/wide_deep/__init__.py\n",
      "A    reco_utils/recommender/wide_deep/wide_deep_utils.py\n",
      "A    reco_utils/tuning\n",
      "A    reco_utils/tuning/__init__.py\n",
      "A    reco_utils/tuning/nni\n",
      "A    reco_utils/tuning/nni/ncf_training.py\n",
      "A    reco_utils/tuning/nni/ncf_utils.py\n",
      "A    reco_utils/tuning/nni/nni_utils.py\n",
      "A    reco_utils/tuning/nni/svd_training.py\n",
      "A    reco_utils/tuning/parameter_sweep.py\n",
      "Checked out revision 10104.\n"
     ]
    }
   ],
   "source": [
    "!svn checkout https://github.com/microsoft/recommenders/trunk/reco_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.7.6 (default, Dec 19 2019, 23:50:13) \n",
      "[GCC 7.4.0]\n",
      "Pandas version: 0.25.3\n",
      "Tensorflow version: 1.15.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "from reco_utils.recommender.ncf.ncf_singlenode import NCF\n",
    "from reco_utils.recommender.ncf.dataset import Dataset as NCFDataset\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.common.notebook_utils import is_jupyter\n",
    "from reco_utils.dataset.python_splitters import python_chrono_split\n",
    "from reco_utils.evaluation.python_evaluation import rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Pandas version: {}\".format(pd.__version__))\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top k items to recommend\n",
    "TOP_K = 10\n",
    "\n",
    "# Model parameters\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../Data/train.csv', names=['user_id', 'profile_id', 'rating'])\n",
    "test = pd.read_csv('../Data/test.csv', names=['user_id', 'profile_id', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NCFDataset(train=train, test=test, col_user='user_id', col_item= 'profile_id', seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NCF (\n",
    "    n_users=data.n_users, \n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=8,\n",
    "    layer_sizes=[32,16,8],\n",
    "    n_epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=1,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 [15.48s]: train_loss = 0.359371 \n",
      "Epoch 2 [15.34s]: train_loss = 0.279874 \n",
      "Epoch 3 [17.96s]: train_loss = 0.254373 \n",
      "Epoch 4 [16.58s]: train_loss = 0.239457 \n",
      "Epoch 5 [16.11s]: train_loss = 0.230343 \n",
      "Epoch 6 [14.89s]: train_loss = 0.222742 \n",
      "Epoch 7 [16.82s]: train_loss = 0.216937 \n",
      "Epoch 8 [17.07s]: train_loss = 0.212384 \n",
      "Epoch 9 [17.66s]: train_loss = 0.208327 \n",
      "Epoch 10 [16.46s]: train_loss = 0.205183 \n",
      "Took 164.39965653419495 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "model.fit(data)\n",
    "\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predictions'] = test.apply(lambda x: model.predict(x.user_id, x.profile_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['predictions'] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = sqrt(mean_squared_error(test['rating'].values, test['predictions'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.313171179775356\n"
     ]
    }
   ],
   "source": [
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] = train.apply(lambda x: model.predict(x.user_id, x.profile_id), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['predictions'] *= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = sqrt(mean_squared_error(train['rating'].values, train['predictions'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.15754817832538"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/user2id_embedding.pickle', 'wb')\n",
    "pickle.dump(model.user2id, f)  \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/item2id_embedding.pickle', 'wb')\n",
    "pickle.dump(model.item2id, f)  \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/id2user_embedding.pickle', 'wb')\n",
    "pickle.dump(model.id2user, f)  \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/id2item_embedding.pickle', 'wb')\n",
    "pickle.dump(model.id2item, f)  \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/user2id_embedding.pickle','rb') \n",
    "user2id_embedding = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/item2id_embedding.pickle','rb') \n",
    "item2id_embedding = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/id2user_embedding.pickle','rb') \n",
    "id2user_embedding = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('model/id2item_embedding.pickle','rb') \n",
    "id2item_embedding = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = NCF (\n",
    "    n_users=data.n_users, \n",
    "    n_items=data.n_items,\n",
    "    model_type=\"NeuMF\",\n",
    "    n_factors=8,\n",
    "    layer_sizes=[32,16,8],\n",
    "    n_epochs=10,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    learning_rate=1e-3,\n",
    "    verbose=1,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.load(neumf_dir='model')\n",
    "model1.user2id = user2id_embedding\n",
    "model1.item2id = item2id_embedding\n",
    "model1.id2user = id2user_embedding\n",
    "model1.id2item = id2item_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['predictions1'] = train.apply(lambda x: model1.predict(x.user_id, x.profile_id), axis=1)\n",
    "train['predictions1'] *= 10\n",
    "\n",
    "rms = sqrt(mean_squared_error(train['rating'].values, train['predictions1'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rec systems",
   "language": "python",
   "name": "mark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
